{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 3_ER_Submitted.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdrQZbrveQZnWA4wiBfqMW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erinmr/ATLS-5519/blob/main/Day_3_ER_Submitted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day 3 - June 2, 2022\n",
        "We covered problems 7 and 8. Problem 9 was homework. \n",
        "\n",
        "Problem 7 was to count syllables using the CMU_dict and creating an exception dictionary with missing. \n",
        "\n",
        "Problem 8 was modified to create a line of poetry with a user-specified number of syllables using the Markov model 1 \n",
        "\n",
        "Problem 9 was to test a set of random words from diction 2of4brif.txt with the syllable counter in Problem 7. "
      ],
      "metadata": {
        "id": "Cu0R9RD7EfBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This first section sets up the CMU dict, which is a phoentic dictionary and missing words file to create our corpus. "
      ],
      "metadata": {
        "id": "rF_YPGUAiP5j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRGNWDbd0JT0",
        "outputId": "43cdd0df-9f8b-4bac-f796-cfbb6a1da481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"Find words in haiku corpus missing from cmudict & build exceptions dict.\"\"\"\n",
        "import nltk\n",
        "nltk.download('cmudict')\n",
        "  \n",
        "\n",
        "import sys\n",
        "from string import punctuation\n",
        "import pprint\n",
        "import json\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "cmudict = cmudict.dict()  # Carnegie Mellon University Pronouncing Dictionary\n",
        "\n",
        "def load_haiku(filename):\n",
        "    \"\"\"Open and return training corpus of haiku as a set.\"\"\"\n",
        "    with open(filename) as in_file:\n",
        "        haiku = set(in_file.read().replace('-', ' ').split())\n",
        "        return haiku\n",
        "\n",
        "def cmudict_missing(word_set):\n",
        "    \"\"\"Find and return words in word set missing from cmudict.\"\"\"\n",
        "    exceptions = set()\n",
        "    for word in word_set:\n",
        "        word = word.lower().strip(punctuation)\n",
        "        if word.endswith(\"'s\") or word.endswith(\"â€™s\"):\n",
        "            word = word[:-2]\n",
        "        if word not in cmudict:\n",
        "            exceptions.add(word)\n",
        "    print(\"\\nexceptions:\")\n",
        "    print(*exceptions, sep='\\n')\n",
        "    print(\"\\nNumber of unique words in haiku corpus = {}\".format(len(word_set)))\n",
        "    print(\"Number of words in corpus not in cmudict = {}\"\n",
        "          .format(len(exceptions)))\n",
        "    membership = (1 - (len(exceptions) / len(word_set))) * 100\n",
        "    print(\"cmudict membership = {:.1f}{}\".format(membership, '%'))\n",
        "    return exceptions\n",
        "\n",
        "def make_exceptions_dict(exceptions_set):\n",
        "    \"\"\"Return dictionary of words and syllable counts from set of words.\"\"\"\n",
        "    missing_words = {}\n",
        "    print(\"Input # syllables in word. Mistakes can be corrected at end. \\n\")\n",
        "    for word in exceptions_set:\n",
        "        while True:\n",
        "            num_sylls = input(\"Enter number syllables in {}: \".format(word))\n",
        "            if num_sylls.isdigit():\n",
        "                break\n",
        "            else:\n",
        "                print(\"                   Not a valid answer!\", file=sys.stderr)                    \n",
        "        missing_words[word] = int(num_sylls)              \n",
        "    print()\n",
        "    pprint.pprint(missing_words, width=1)\n",
        "\n",
        "    print(\"\\nMake Changes to Dictionary Before Saving?\")\n",
        "    print(\"\"\"\n",
        "    0 - Exit & Save\n",
        "    1 - Add a Word or Change a Syllable Count \n",
        "    2 - Remove a Word\n",
        "    \"\"\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"\\nEnter choice: \")   \n",
        "        if choice == '0':\n",
        "            break\n",
        "        elif choice == '1':\n",
        "            word = input(\"\\nWord to add or change: \")\n",
        "            missing_words[word] = int(input(\"Enter number syllables in {}: \"\n",
        "                                            .format(word)))\n",
        "        elif choice == '2':\n",
        "            word = input(\"\\nEnter word to delete: \")\n",
        "            missing_words.pop(word, None)\n",
        "            \n",
        "    print(\"\\nNew words or syllable changes:\")\n",
        "    pprint.pprint(missing_words, width=1)\n",
        "\n",
        "    return missing_words\n",
        "\n",
        "def save_exceptions(missing_words):\n",
        "    \"\"\"Save exceptions dictionary as json file.\"\"\"\n",
        "    json_string = json.dumps(missing_words)\n",
        "    f = open('missing_words.json', 'w')\n",
        "    f.write(json_string)\n",
        "    f.close()\n",
        "    print(\"\\nFile saved as missing_words.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Only run this if you need to build the missing_words.json file "
      ],
      "metadata": {
        "id": "LdsksSD4Ib8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "haiku = load_haiku('train.txt')\n",
        "exceptions = cmudict_missing(haiku)\n",
        "build_dict = input(\"\\nManually build an exceptions dictionary (y/n)? \\n\")\n",
        "if build_dict.lower() == 'n':\n",
        "    sys.exit()\n",
        "else:\n",
        "    missing_words_dict = make_exceptions_dict(exceptions)\n",
        "    save_exceptions(missing_words_dict)"
      ],
      "metadata": {
        "id": "6i4gKNggIa6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 7: Syllable counter \n",
        "\n",
        "Objective: Write a Python program that counts the number of syllables in an English word or phrase.\n",
        "\n",
        "Things to consider: \n",
        "- List of vowel sounds or instead look for numbers at the end of phenomes \n",
        "\n",
        "\n",
        "Pseudocode:\n",
        "- count vowels by the string with a number approach\n",
        " - creat a list of all vowel string sounds (ALT - look for numbers at the end \n",
        " - allow user to input a word or phrase \n",
        " - Load CMU Dictionary\n",
        " - Load missing_words.json\n",
        " - Loop on input determine if this is a word or phrase \n",
        " - if phrase separate each word at the space \n",
        " - if word no spaces found\n",
        " - for each word\n",
        "    - count the number of times the vowels occur in the word\n",
        "      - Check in missing_words and add to a counter\n",
        "      - else look in dictionary file for the word(s)\n",
        "        - look for numbers at the end of phenomes to indicate vowles (and syllabuls) and add to counter  \n",
        "   \n",
        " - print word or phrase and counter total number of syllables \n",
        " - Similar to approach yesterday to count letters \n"
      ],
      "metadata": {
        "id": "9sNqw6T_0SBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from string import punctuation\n",
        "import json\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "cmudict = cmudict.dict()\n",
        "\n",
        "with open('missing_words.json') as f: \n",
        "  missing_words = json.load(f)\n",
        " # print(missing_words)\n",
        "\n",
        "def count_syllables(words): #some user input (word or phrase)\n",
        "  num_sylls = 0 \n",
        " \n",
        "  for word in words.lower().split(): \n",
        "   # print(word)\n",
        "\n",
        "    if word in missing_words: \n",
        "      num_sylls += missing_words[word]\n",
        "      #print(word)\n",
        "    \n",
        "    elif word in cmudict.keys():\n",
        "      #print(word) \n",
        "      for phonemes in cmudict[word][0]:\n",
        "        for phoneme in phonemes:\n",
        "          #print(phoneme)\n",
        "          if phoneme.isdigit():\n",
        "            num_sylls += 1\n",
        "    else: \n",
        "      a_missing_word = input(\"We don't have that word. How many syllables does it have?\")\n",
        "      a_missing_word = int(a_missing_word)\n",
        "      num_sylls = num_sylls + a_missing_word\n",
        "\n",
        "  return num_sylls\n",
        "\n",
        "\n",
        "word = input(\"Enter a word or phrase\")\n",
        "num_syllables = count_syllables(word)\n",
        "print(num_syllables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uiJjs_90Td8",
        "outputId": "4df2e0a3-aa6f-4f78-9e04-fad470c5fca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a word or phrasecat\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 8 - Poetry Line Generator \n",
        "\n",
        "\n",
        "Objective: Write a program that generates haiku using Markov chain analysis. Allow the user to modify the haiku by independently regenerating lines two and three.\n",
        "\n",
        "standing still at dusk\n",
        "listen... in far distances \n",
        "the song of frogglings\n",
        "\n",
        "x:y\n",
        "'standing': 'still' \n",
        "\n",
        "'x y': 'z' \n",
        "'standing still': 'at'\n",
        "'still at': 'dusk' \n",
        "\n",
        "Pseudocode:\n",
        "- load training file \n",
        "- Clean up corpus for punctuation \n",
        "- build models \n",
        "  - Markov 1 (first word predicts second word)\n",
        "  - Markov 2 (first two words predict third word)\n",
        "- line creation function that leverages Markov 1 and 2\n",
        "- user enters number of syllables for the phrase (target sylls) \n",
        "- Identify word 1 by picking random word or seeding word or phrase from user\n",
        "- count syllables of word 1 = num sylls\n",
        "- set phrase = to word 1\n",
        "- while num sylls < target sylls find new word and count word sylls. if num sylls + new sylls <= add word to phrase and set word = new word \n",
        "- Print phrase \n",
        "\n"
      ],
      "metadata": {
        "id": "ujFuHEdK0bqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from string import punctuation\n",
        "import json\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "cmudict = cmudict.dict()\n",
        "\n",
        "with open('missing_words.json') as f: \n",
        "  missing_words = json.load(f)\n",
        " # print(missing_words)\n",
        "\n",
        "def count_syllables(words): #some user input (word or phrase)\n",
        "  num_sylls = 0 \n",
        " \n",
        "  for word in words.lower().split(): \n",
        "\n",
        "    if word in missing_words: \n",
        "      num_sylls += missing_words[word]\n",
        "    \n",
        "    elif word in cmudict.keys():\n",
        "      #print(word) \n",
        "      for phonemes in cmudict[word][0]:\n",
        "        for phoneme in phonemes:\n",
        "          #print(phoneme)\n",
        "          if phoneme.isdigit():\n",
        "            num_sylls += 1\n",
        "    else: \n",
        "      a_missing_word = input(f\"We don't have the word {word}. How many syllables does it have?\")\n",
        "      a_missing_word = int(a_missing_word)\n",
        "      num_sylls = num_sylls + a_missing_word\n",
        "\n",
        "  return num_sylls\n",
        "\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "with open('train.txt') as f:\n",
        "  raw_haiku = f.read()\n",
        "  \n",
        "#cleaning up the corpus for weird punctuation \n",
        "corpus = raw_haiku.replace('\\n', ' ')\n",
        "corpus = corpus.replace('!', '')\n",
        "corpus = corpus.replace(',', '')\n",
        "corpus = corpus.replace('-', ' ')\n",
        "corpus = corpus.replace('?', '')\n",
        "corpus = corpus.replace(\"'s\", '')\n",
        "corpus = corpus.replace(':', '')\n",
        "corpus = corpus.replace('\"', '')\n",
        "corpus = corpus.replace('.', '')\n",
        "corpus = corpus.split()\n",
        "\n",
        "#create Markov Model for one word\n",
        "def map_word_to_word(corpus):\n",
        "  limit = len(corpus)-1\n",
        "  dict1_to_1 = defaultdict(list)\n",
        "  \n",
        "  for index, word in enumerate(corpus):\n",
        "    if index < limit:\n",
        "      suffix = corpus[index+1]\n",
        "      dict1_to_1[word].append(suffix)\n",
        "\n",
        "  return(dict1_to_1)\n",
        "\n",
        "#create Markov Model for two word phrase\n",
        "def map_2_words_to_word(corpus):\n",
        "  limit = len(corpus)-2\n",
        "  dict2_to_1 = defaultdict(list)\n",
        "  \n",
        "  for index, word in enumerate(corpus):\n",
        "    if index < limit:\n",
        "      key = word + ' ' + corpus[index+1]\n",
        "      suffix = corpus[index+2]\n",
        "      #suffix = corpus[index+1]\n",
        "      dict2_to_1[key].append(suffix)\n",
        "\n",
        "  return(dict2_to_1)\n",
        "\n",
        "# pull a random word from the corpus \n",
        "def random_word(corpus):\n",
        "  word = random.choice(corpus)\n",
        "  num_sylls = count_syllables(word)\n",
        "  return(word,num_sylls)\n",
        "\n",
        "# gather the next word after the current word\n",
        "def word_after(prefix, suffix_map, current_syls, target_syls):\n",
        "  accepted_words = []\n",
        "  suffixes = suffix_map.get(prefix)\n",
        "  \n",
        "  for candidate in suffixes:\n",
        "    num_syls = count_syllables(candidate)\n",
        "    if current_syls + num_syls <= target_syls:\n",
        "      accepted_words.append(candidate)              # create a list of words with acceptable syllable counts\n",
        "\n",
        "  final_word = random.choice(accepted_words)        # choose a random word from the accepted list\n",
        " \n",
        "  return(final_word)\n",
        "\n",
        "target_syllables = int(input('Enter number of syllables for phrase (5 or 7):'))\n",
        "word, num_syllables = random_word(corpus)\n",
        "phrase = word\n",
        "\n",
        "while num_syllables < target_syllables:\n",
        "    new_word = word_after(word, map_word_to_word(corpus), num_syllables, target_syllables)\n",
        "    new_syllables = count_syllables(new_word)\n",
        "    if num_syllables + new_syllables <= target_syllables:       # if nbew word is within\n",
        "        phrase = phrase + \" \" + new_word\n",
        "        num_syllables += new_syllables\n",
        "        word = new_word\n",
        "\n",
        "print(f'Your poetry line is: {phrase} ({count_syllables(phrase)} syllables)')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RZ_2MjX0adv",
        "outputId": "dd03f3db-bca1-4e9e-88ff-c30a94eba22a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter number of syllables for phrase (5 or 7):5\n",
            "Your poetry line is: do your very bones (5 syllables)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 9 - Test Syllable Counter \n",
        "With user defined number of random words \n",
        "\n",
        "Pseudocode:\n",
        "1. load in the new corpus - 2of4brif.txt\n",
        "2. Ask the user how many words to test \n",
        "2. strip the word list to remove any leading/trailing spaces \n",
        "3. set j = 0\n",
        "4. While j is less than or equal to the target num of words set by the user\n",
        "- generate a random number \n",
        "- use that as the index in the corpus to find a word \n",
        "- run the count syllable function\n",
        "- if the word is not found enter the number of syllables \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0cr12LdbID-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/2of4brif.txt\", 'r')  # open the dictionary file \n",
        "\n",
        "target_num_words = int(input('Enter number of words to test:'))  # get target number of words to test \n",
        "words_list = f.readlines()\n",
        "\n",
        "for i in range(len(words_list)): \n",
        "  words_list[i] = words_list[i].strip()\n",
        "\n",
        "j=0\n",
        "\n",
        "while j <= target_num_words-1:\n",
        "  random_number = random.randint(0,len(words_list)-1)\n",
        "  word = words_list[random_number]\n",
        "  syllables = count_syllables(word)\n",
        "  print(f'the word is {word} and it has {syllables} syllables')\n",
        "  j +=1 \n",
        "  print(j)\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "  \n",
        "\n",
        "#print(random_number1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLmU__F30w0L",
        "outputId": "3baa51a3-460a-4264-8c51-71967683d178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter number of words to test:18\n",
            "We don't have the word teatimes. How many syllables does it have?1\n",
            "the word is teatimes and it has 1 syllables\n",
            "1\n",
            "We don't have the word lynchpin. How many syllables does it have?2\n",
            "the word is lynchpin and it has 2 syllables\n",
            "2\n",
            "We don't have the word vaccinates. How many syllables does it have?3\n",
            "the word is vaccinates and it has 3 syllables\n",
            "3\n",
            "the word is initiative and it has 4 syllables\n",
            "4\n",
            "the word is piranha and it has 3 syllables\n",
            "5\n",
            "We don't have the word backcloth. How many syllables does it have?2\n",
            "the word is backcloth and it has 2 syllables\n",
            "6\n",
            "the word is readying and it has 3 syllables\n",
            "7\n",
            "the word is snippet and it has 2 syllables\n",
            "8\n",
            "the word is sickle and it has 2 syllables\n",
            "9\n",
            "the word is way and it has 1 syllables\n",
            "10\n",
            "the word is cites and it has 1 syllables\n",
            "11\n",
            "We don't have the word roguishly. How many syllables does it have?3\n",
            "the word is roguishly and it has 3 syllables\n",
            "12\n",
            "the word is bottoms and it has 2 syllables\n",
            "13\n",
            "the word is incorrect and it has 3 syllables\n",
            "14\n",
            "the word is minoring and it has 3 syllables\n",
            "15\n",
            "the word is pinion and it has 2 syllables\n",
            "16\n",
            "We don't have the word denier. How many syllables does it have?2\n",
            "the word is denier and it has 2 syllables\n",
            "17\n",
            "We don't have the word anglicises. How many syllables does it have?3\n",
            "the word is anglicises and it has 3 syllables\n",
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ¨ made it through the first week! "
      ],
      "metadata": {
        "id": "hu4PvoXyiDst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WIbr2_-aa8zC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}